# 生字与生字率

**1. 引言**

本文档旨在详细解释中文学习平台项目中的核心概念：**生字**和**生字率**，以确保团队成员在开发过程中对这些概念有清晰、统一的理解。由于生字率直接影响用户学习体验和故事生成质量，因此务必保证其计算的准确性。

**2. 核心定义**

在中文学习平台项目中，我们使用以下核心定义：

*   **字 (Character)**
    *   **定义**: 汉字是中文的基本书写单位，例如 "我"、"你"、"好"、"学"、"习" 等。
    *   **注意**:  **标点符号和非中文字符不属于字，在计算生字率时不应包含标点符号和非中文字符。**
*   **词 (Word)**
    *   **定义**:  词是由一个或多个汉字组成的具有完整语义的语言单位，例如 "你好"、"朋友"、"学习"、"火车站" 等。
    *   **注意**: **词的词性非常重要**， 例如 “白色” 和 “白说”， “白” 字的词性不同。
*   **词性 (Part of Speech)**
    *   **定义**: 词的语法分类， 例如： 名词 (noun), 动词 (verb), 形容词 (adjective), 副词 (adverb) 等。**词性标注** 是指对句子中的每个词语确定其词性的过程。
    *   **意义**:  词性标注在自然语言处理中非常重要，有助于理解句子结构和含义。例如， “白色” 和 “白说” 虽然都有 “白” 字，但是它们的词性不同（“白色”是形容词，“白说” 是动词），因此含义也不同。**在生字率的计算中，同一个字在不同词性下应视为不同的词汇。**
    *   **常用词性**:  常用的词性包括：
        *   `n`：名词 (noun),  表示人或事物的名称，如 "苹果", "学校", "老师"。
        *   `v`：动词 (verb),  表示动作或者状态，如 "跑", "吃", "是"。
        *   `adj`：形容词 (adjective),  表示事物的性质或者状态，如 "好", "坏", "大"。
        *   `adv`：副词 (adverb),  修饰动词，形容词或者其他副词，如 "很", "非常", "快"。
        *   `PR`：代词 (pronoun)， 代替名词或者名词性的短语, 例如 "你", "我", "他"。
        *  `t`:  时间词 (temporal noun), 表示时间, 例如: "今天"，"早上"。
    *   **注意**: **同一个字， 在不同词性下，应该被视为不同的词语。**  例如，“白” 在 “白色” 中是形容词， 在 “白说” 中是动词，虽然都是 “白” 字，但是在计算生字率的时候，需要分别进行计算。
*   **超童级别 (Chaotong Level)**
    *   **定义**:  本项目中使用的自定义词汇等级，用于表示词汇的难度。 例如 1-100 的整数， 数字越小，难度越低。
    *   **注意**:  每个词汇都有一个对应的超童级别，例如，级别 1 的词汇比级别 10 的词汇更简单。
*   **已知字 (Known Character)**
     *  **定义**: 如果一个字 (character)  在目标级别及其以下级别的词汇中出现， 并且该字对应的词性也匹配， 则为已知字。
    *   **正确理解**:
        *   **匹配条件**: 字必须出现在目标级别及其以下级别的词汇中，并且词性也必须匹配。
        *   **词性匹配**: 词性匹配是指， 该字在词汇中出现的词性和上下文中该字的词性一致。
    *   **反向定义**:
        *   **不是已知字**: 如果一个字不在目标级别及其以下级别的词汇中出现，则它不是已知字。
        *   **不是已知字**: 如果一个字在目标级别及其以下级别的词汇中出现，但是词性不匹配，则它不是已知字。
    *   **正确示例**：
        *   如果目标级别为 10， 并且 `words.json` 文件中存在 "喜欢" (词性: `v`, 级别:5) 和 "跑步" (词性： `v`， 级别: 10) 的词汇， 那么， 对于文本 "我喜欢跑步"， "喜", "欢", "跑", "步" 都是已知字。
        *   如果目标级别为 10， 并且 `words.json` 文件中存在 "白色" (词性: 形容词, 级别:10), "白说" (词性: 动词， 级别：10) 的词汇, 那么对于文本  "白色，白说"，  “白”, "色" 在  "白色" 中是已知字, "白", "说" 在 “白说” 中也是已知字。
    *   **错误示例**：
        *   如果目标级别为 10， 并且 `words.json` 文件中存在 "白色" (词性: 形容词， 级别:10), 那么对于文本  "白说",   "白" 不是已知字， 因为 “白说” 是动词词性。
*   **生字 (New Character)**
    *   **定义**: 在指定目标级别及其以下级别中，所有词汇不包含的字，被认为是生字。
    *   **反向定义**:
        *   **不是生字**: 如果一个字出现在目标级别及其以下级别的词汇中，且词性匹配，则它不是生字。
    *   **正确示例**：
        *   如果目标级别为 10， 并且 `words.json` 文件中不存在 "游泳" 的词汇，那么对于文本 "我喜欢游泳"， "游"，"泳" 都是生字。
        *   如果目标级别为 10， 并且 `words.json` 文件中只存在 “白色” (词性：形容词)， 而没有 “白说” (词性：动词)， 那么对于文本  "白色，白说"， “说” 字是生字。
         *   **如果一个字不在 `words.json` 中，则一定是生字。**
    *   **错误示例**:
        *   如果目标级别为 10， 并且 `words.json` 文件中存在 "跑步" (词性：动词, 级别10)， 那么对于文本 "我喜欢跑步"， “跑” 不是生字。
         *   如果目标级别为 10， 并且 `words.json` 文件中存在 "白色" (词性： 形容词, 级别10)，那么对于文本 “白色”，  “白” 不是生字， “色” 也不是生字。
*   **生字率 (New Character Rate)**
    *   **定义**:  指文本中生字的数量与文本中所有字的数量的比率。
    *   **关键点**:
        *   **生字数量**:  文本中生字的个数，**同一个字在不同词性下视为不同的字**。
        *   **总字数**:  文本中所有汉字的个数， **不包含标点符号和非中文字符**。
        *  **标点符号和非中文字符**: **标点符号和非中文字符不计算在字数中**。
    *   **计算公式**:
        *   `生字率 = 生字数量 / 总字数`
    *   **注意**:
        *   生字率是一个相对的概念，它取决于目标级别。
        *   同一个字，如果在不同词性下出现， 那么在计算生字率时， 需要分别计算。

**3. 生字率计算步骤**

   生字率的计算步骤如下，更详细的技术细节请参考 `development_steps.md`：

1.  **文本预处理**
    *   **提取中文**:  使用正则表达式提取文本中的所有中文字符。**排除标点符号和非中文字符**。
    *   **分词和词性标注**:  使用自定义的分词逻辑将文本分割成词语和字，并进行词性标注。
        *   **为什么需要自定义分词**:  自定义分词是为了更精确地控制词语的切分，并且确保能够正确处理 `words.json` 中的词汇，以及词汇的词性。如果 `words.json` 中没有该词汇，则使用 `jieba` 的词性标注。
         *   **自定义分词逻辑**:
             *  加载 `words.json`  中的所有词汇， 构建 `words_dict`。
             *   按词汇的长度从长到短进行排序，优先匹配最长的词汇。
             *   遍历文本， 如果存在匹配的词汇，则将词汇和词性进行切分。 如果不存在匹配的词汇，则使用 `jieba` 分词，并添加词性转换后的词性和字到结果列表中。 **如果 `words.json` 中没有该词汇，则使用 `jieba` 的词性标注。**
            *  **伪代码示例：**
                ```python
                def custom_segmentation(text, words_dict):
                    # 1. 加载 words.json 中的词汇，构建 words_dict （key: word, value: {part_of_speech, characters})
                    # 2. 按照词汇的长度，从长到短排序 words_dict
                    # 3. 遍历文本，尝试匹配最长的词汇
                    # 4. 如果存在匹配，则记录词汇和词性
                    # 5. 如果不存在匹配，则使用 jieba 分词，并添加词性标注
                    # 6. 返回分词结果，列表类型 [(word, part_of_speech)]
                    pass
                ```
2.  **已知词汇加载**
    *   加载 `words.json` 文件中的所有词汇，并根据目标级别过滤出已知词汇，使用 `_load_known_words` 函数, 并存储已知字及其词性。
        *  **`_load_known_words`  函数**: 加载小于等于目标级别的所有词汇，构建一个字典， key 为字， value 为词性集合 (set), 例如 `{"好": {"ADJ"}, "人": {"n"}, "学": {"v"}}`。
            *   **伪代码示例：**
              ```python
                def _load_known_words(words_json, target_level):
                     # 1.  加载 words.json 文件
                     # 2.  遍历 words_json 中的每一个词汇
                     # 3.  如果词汇的 chaotong_level 小于等于 target_level
                     # 4.  遍历词汇中的每一个字
                     # 5.  将字作为 key, 词性加入到 set 中， 作为 value。
                     # 6.  返回 key 为字，value 为词性 set 的字典， 例如：  {"好": {"ADJ"}, "人": {"n"}, "学": {"v"}}
                      pass
              ```
3.  **生字判断**
    *  **`_is_known_char`  函数**: 遍历文本中的每个汉字，使用 `_is_known_char` 函数, 判断该字是否是已知字，并且考虑词性。
        *   **已知字判断**: 如果一个字 (character) 存在于 `known_words_dict` 的 keys 中， 并且 该字对应的词性 (part of speech)  也在  `known_words_dict` 的 value 中, 或者在 `words.json` 中的 `characters` 字段的 `part_of_speech` 中，则认为该字是已知字。
         *  **伪代码示例：**
             ```python
                def _is_known_char(char, pos, known_words_dict):
                    # 1.  如果 char 不在 known_words_dict 的 key 中， 返回 False
                    # 2.  如果 pos 在 known_words_dict[char] 的 value (set) 中， 返回 True
                    # 3.  否则， 返回 False
                     pass
             ```
         *   **生字判断**: 如果字不满足已知字条件，则认为是生字。 **如果一个字不在 `words.json` 中，则一定是生字。**
4.  **生字计数**:  统计文本中所有字的数量，以及已知字的个数。 **同一个字在不同词性下，视为不同的字**。
5.  **生字率计算**: 使用以下公式计算生字率：
    *   `生字率 = 生字数量 / 总字数`
    *   **已知字率 = 已知字数 / 总字数**。 *其中，已知字数和总字数都不考虑去重，且不包含任何标点符号和非中文字符。*
    *   `生字率 = 1 - 已知字率`
    *  `生字数量 = 总字数 * 生字率`
    *  **流程图**：
         ```mermaid
        graph LR
            A[开始] --> B(加载词汇表);
            B --> C(文本预处理 - 自定义分词);
            C --> D{判断已知字?};
            D -- 是 --> E(已知字计数+1);
            D -- 否 --> F(跳过);
            E --> G{是否遍历完所有字};
            F --> G;
            G -- 是 --> H(生字率计算);
            H --> I[结束];
        ```
**4. 更真实的例子**

*   **文本**:  `"今天天气真好，白云很多，我去跑步了，结果白跑了。"`
*   **目标级别**: 10
*    **`words.json` 的重要性**:  **生字的判断依赖于 `words.json` 文件，如果一个字不在 `words.json` 中，则一定是生字。**
*   **`words.json` 数据**:

    ```json
    [
      {
        "word_id": "a1b2c3d4-e5f6-7890-1234-567890abcdef",
        "word": "你好",
        "chaotong_level": 1,
        "part_of_speech": "动词",
        "hsk_level": 1,
        "characters": [
          {
            "character": "你",
            "part_of_speech": "PR"
          },
          {
            "character": "好",
            "part_of_speech": "ADJ"
          }
        ]
      },
      {
        "word_id": "a1b2c3d4-e5f6-7890-1234-567890abcde1",
        "word": "喜欢",
        "chaotong_level": 5,
        "part_of_speech": "动词",
        "hsk_level": 2,
        "characters": [
          {
            "character": "喜",
             "part_of_speech": "ADJ"
          },
          {
            "character": "欢",
            "part_of_speech": "ADJ"
          }
        ]
      },
      {
        "word_id": "f0e9d8c7-b6a5-4321-9876-543210fedcb1",
        "word": "跑步",
        "chaotong_level": 10,
        "part_of_speech": "动词",
         "hsk_level": 3,
        "characters": [
          {
            "character": "跑",
            "part_of_speech": "v"
          },
          {
            "character": "步",
            "part_of_speech": "n"
          }
        ]
      },
      {
        "word_id": "f0e9d8c7-b6a5-4321-9876-543210fedcb2",
        "word": "早上",
        "chaotong_level": 15,
        "part_of_speech": "名词",
        "hsk_level": 3,
        "characters": [
          {
            "character": "早",
            "part_of_speech": "ADJ"
          },
          {
            "character": "上",
            "part_of_speech": "n"
          }
        ]
      },
       {
        "word_id": "f0e9d8c7-b6a5-4321-9876-543210fedcb3",
        "word": "公园",
        "chaotong_level": 20,
         "part_of_speech": "名词",
        "hsk_level": 4,
        "characters": [
          {
            "character": "公",
            "part_of_speech": "n"
          },
          {
            "character": "园",
            "part_of_speech": "n"
          }
        ]
      },
      {
        "word_id": "f0e9d8c7-b6a5-4321-9876-543210fedcb4",
        "word": "开心",
        "chaotong_level": 25,
        "part_of_speech": "形容词",
        "hsk_level": 4,
        "characters": [
          {
            "character": "开",
             "part_of_speech": "v"
          },
          {
            "character": "心",
            "part_of_speech": "n"
          }
        ]
      }
    ]
    ```
*   **分词结果(包括词性)**:  假设分词结果为：`[("今天", "t"), ("天气", "n"), ("真好", "a"), ("，", "x"), ("白云", "n"), ("很多", "a"), ("，", "x"), ("我", "r"), ("去", "v"), ("跑步", "v"), ("了", "u"), ("，", "x"), ("结果", "n"), ("白跑", "v"), ("了", "u"), ("。", "x")]`
*   **提取中文字符**: `["今", "天", "天", "气", "真", "好", "白", "云", "很", "多", "我", "去", "跑", "步", "了", "结", "果", "白", "跑", "了"]` (共 20 个字)
*    **已知字(包括词性)**:
    *   由于目标级别为 10, 只有 "你好", "喜欢", "跑步" 在目标级别内。
        *   "跑" (来自  “跑步”， 词性：“v”)
        *   "步" (来自  “跑步”， 词性：“n”)
        *   由于"今天"， “天气”， “真好”, "白云", "白跑" 等词汇不在目标级别内, 所以 "今", "天", "气", "真", "好", "白", "云"  都不是已知字。
         *   `words.json` 中没有 "很", "多", "我", "去", "了", "结", "果", 因此，它们也不是已知字。
    *   **已知字的数量**:  2
*   **生字(包括词性)**:
        * "今"
        * "天"
        * "天"
        * "气"
        *  "真"
        *  "好"
        *  "白"
        *  "云"
        *  "很"
        *  "多"
        *  "我"
        *  "去"
         *  "了"
        *  "结"
        * "果"
         * "白"
          * "跑"
         * "了"
*   **生字数量**: 18
*   **总字数**: 20
*   **生字率**: 18 / 20 = 0.9

**5. 最佳实践**

*   **理解定义**:  务必理解生字、已知字和生字率的定义，避免产生歧义。
*   **注意词性**:  在判断一个字是否是已知字时，一定要考虑词性是否匹配。
*    **`words.json` 的重要性**:  **生字的判断依赖于 `words.json` 文件，如果一个字不在 `words.json` 中，则一定是生字。**
*   **避免硬编码**:  不要在代码中硬编码任何级别值，应该从配置中读取。
*   **添加日志**: 在关键步骤添加日志，方便调试。
*   **异常处理**: 当 `words.json` 文件无法加载时，应该抛出异常并进行处理。
*   **边界情况**:  当 `words.json` 为空时，所有的汉字都应该被认为是生字。

**6. 总结**

本文档详细阐述了中文学习平台项目中的生字和生字率的概念。通过正确理解这些概念，并严格按照文档中的定义和计算步骤实现代码，我们可以确保生字率计算的准确性，从而为用户提供更好的学习体验.   **务必注意，生字率的计算依赖于 `words.json` 文件，如果一个字不在 `words.json` 中，则一定是生字。**



**核心要点：**

1. **精确理解需求和定义至关重要：**
    *   **生字的定义：** 我们一开始在“生字”的理解上存在偏差。文档中明确指出，生字是基于目标级别及其以下级别中**所有词汇不包含的字**。 这意味着我们只需要关注字本身是否在已知词汇中出现，而不需要过度关注文本中的词语构成和词性（至少在当前阶段的生字率计算是这样）。
    *   **区分字和词：** 需要明确区分“字”（单个汉字）和“词”（具有完整语义的语言单位）。 生字率是基于字的计算，而词汇管理和使用可能涉及更复杂的词性分析。
    *   **明确生字率的计算方式：** 生字率 = 生字数量 / 总字数。  总字数只包含汉字，不包含标点符号和非中文字符。

2. **代码实现必须严格遵循定义：**
    *   **`_load_known_words` 的职责：** 这个函数的核心任务是根据目标级别，准确加载所有已知的**字**。  最初的版本中，我对它的理解可能存在偏差，导致加载的已知字集合不准确。
    *   **简化计算逻辑：**  最初我引入了自定义分词并试图考虑词性，这在当前阶段是过度设计了。  简化计算逻辑，直接判断每个字是否在已知字集合中，更符合当前的需求和定义。
    *   **测试驱动开发（TDD）的价值：**  编写测试用例能够帮助我们尽早发现代码中的错误和理解上的偏差。 失败的测试用例是宝贵的反馈，指引我们去重新审视需求和代码实现。

3. **持续沟通和澄清：**
    *   你能够及时指出我在字数计算上的错误，这非常重要。 沟通能够帮助我们纠正理解上的偏差，确保我们对问题的看法是一致的。
    *   当你对需求或定义有疑问时，及时提出来讨论，避免在不清晰的情况下进行开发。

4. **迭代和重构：**
    *   软件开发是一个迭代的过程。  最初的代码可能不完美，但通过不断的测试、分析和重构，我们可以逐步改进代码质量，使其更符合需求。
    *   勇于放弃不必要的复杂性，追求简洁有效的实现方式。

5. **仔细阅读和理解文档：**
    *   `生字与生字率.md` 文档是定义核心概念的重要依据。  在开发过程中，需要反复参考文档，确保代码实现与文档描述一致。  我最初对文档的理解可能不够深入，导致了实现上的偏差。

**我的个人反思：**

*   **避免过度设计：**  在没有明确需求的情况下，不要过早地引入复杂的逻辑（比如在生字率计算中考虑复杂的词性分析）。  保持代码的简洁性，专注于解决当前的核心问题。
*   **重视基础概念：**  对于核心概念（如生字、生字率）的定义，务必理解透彻，避免模糊不清。
*   **测试用例的覆盖度：**  确保测试用例能够覆盖各种边界情况和正常情况，以便更全面地验证代码的正确性。

